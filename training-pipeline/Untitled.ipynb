{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91b3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.50)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.50 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.34.50)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.50->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.50->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.50->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b491db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b97b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "pipeline_name = f\"sagemaker-mlops-train-pipeline\"\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_client = boto3.resource('s3')\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "default_bucket= sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"ChurnModelPackageGroup\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc347dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "ParameterInteger,\n",
    "ParameterString,\n",
    "ParameterFloat)\n",
    "\n",
    "auc_score_threshold = 0.75\n",
    "base_job_prefix = 'churn-example'\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString( name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "training_instance_type = ParameterString( name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "model_approval_status = ParameterString( name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8870cb6",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d36e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 22:11:46--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/dataset/storedata_total.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2713209 (2.6M) [application/octet-stream]\n",
      "Saving to: ‘storedata_total.xlsx.1’\n",
      "\n",
      "100%[======================================>] 2,713,209   --.-K/s   in 0.02s   \n",
      "\n",
      "2024-02-26 22:11:46 (155 MB/s) - ‘storedata_total.xlsx.1’ saved [2713209/2713209]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/dataset/storedata_total.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea88a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:81: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_excel('storedata_total.xlsx')\n",
    "store_data.to_csv(\"storedata_total.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a09755",
   "metadata": {},
   "source": [
    "## Processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b888d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 22:11:54--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/preprocess-churn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2156 (2.1K) [text/plain]\n",
      "Saving to: ‘preprocess-churn.py.1’\n",
      "\n",
      "100%[======================================>] 2,156       --.-K/s   in 0s      \n",
      "\n",
      "2024-02-26 22:11:54 (38.8 MB/s) - ‘preprocess-churn.py.1’ saved [2156/2156]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/preprocess-churn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd52d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtempfile\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\r\n",
      "    base_dir = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Read Data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df = pd.read_csv(\u001b[37m\u001b[39;49;00m\r\n",
      "        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/input/storedata_total.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    )\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# convert created column to datetime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Convert firstorder and lastorder to datetime datatype\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],errors=\u001b[33m'\u001b[39;49;00m\u001b[33mcoerce\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],errors=\u001b[33m'\u001b[39;49;00m\u001b[33mcoerce\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Drop Rows with Null Values\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df = df.dropna()\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Create column which gives the days between the last order and the first order\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirst_last_days_diff\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = (df[\u001b[33m'\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] - df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).dt.days\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Create column which gives the days between the customer record was created and the first order\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df[\u001b[33m'\u001b[39;49;00m\u001b[33mcreated_first_days_diff\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = (df[\u001b[33m'\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] - df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).dt.days\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Drop columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mcustid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m, inplace=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m#Apply one hot encoding on favday and city columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    df = pd.get_dummies(df, prefix=[\u001b[33m'\u001b[39;49;00m\u001b[33mfavday\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], columns=[\u001b[33m'\u001b[39;49;00m\u001b[33mfavday\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Split into train, validation and test datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    y = df.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mretained\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    X_pre = df\u001b[37m\u001b[39;49;00m\r\n",
      "    y_pre = y.to_numpy().reshape(\u001b[36mlen\u001b[39;49;00m(y), \u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    X = np.concatenate((y_pre, X_pre), axis=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    np.random.shuffle(X)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Split in Train, Test and Validation Datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    train, validation, test = np.split(X, [\u001b[36mint\u001b[39;49;00m(\u001b[34m.7\u001b[39;49;00m*\u001b[36mlen\u001b[39;49;00m(X)), \u001b[36mint\u001b[39;49;00m(\u001b[34m.85\u001b[39;49;00m*\u001b[36mlen\u001b[39;49;00m(X))])\u001b[37m\u001b[39;49;00m\r\n",
      "    train_rows = np.shape(train)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "    validation_rows = np.shape(validation)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "    test_rows = np.shape(test)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\r\n",
      "    train = pd.DataFrame(train)\u001b[37m\u001b[39;49;00m\r\n",
      "    test = pd.DataFrame(test)\u001b[37m\u001b[39;49;00m\r\n",
      "    validation = pd.DataFrame(validation)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Convert the label column to integer\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    train[\u001b[34m0\u001b[39;49;00m] = train[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    test[\u001b[34m0\u001b[39;49;00m] = test[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    validation[\u001b[34m0\u001b[39;49;00m] = validation[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    \u001b[37m# Save the Dataframes as csv files\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\r\n",
      "    train.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/train/train.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    validation.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/validation/validation.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n",
      "    test.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/test/test.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize \"preprocess-churn.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75c71770",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"storedata_total.csv\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039cd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b548b336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "framework_version = \"1.0-1\"\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=framework_version,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-churn-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                         destination=f\"s3://{default_bucket}/output/train\" ),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/test\")\n",
    "    ],\n",
    "    code=f\"preprocess-churn.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5042fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_process = ProcessingStep(name=\"ChurnModelProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c1e7e",
   "metadata": {},
   "source": [
    "## Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67bbc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import (\n",
    "        IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner)\n",
    "from sagemaker.workflow.steps import TuningStep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19d140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1c66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_hyperparameters = {\n",
    "\"eval_metric\":\"auc\",\n",
    "\"objective\":\"binary:logistic\",\n",
    "\"num_round\":\"100\",\n",
    "\"rate_drop\":\"0.3\",\n",
    "\"tweedie_variance_power\":\"1.4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "619d4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"churn-train\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457fb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "\"eta\": ContinuousParameter(0, 1),\n",
    "\"min_child_weight\": ContinuousParameter(1, 10),\n",
    "\"alpha\": ContinuousParameter(0, 2),\n",
    "\"max_depth\": IntegerParameter(4, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd226da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_train,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef5e0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_args = tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f9d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_tuning = TuningStep(\n",
    "    name=\"ChurnHyperParameterTuning\",\n",
    "    step_args=hpo_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa072e",
   "metadata": {},
   "source": [
    "## Evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a12e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 22:11:55--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/evaluate-churn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1309 (1.3K) [text/plain]\n",
      "Saving to: ‘evaluate-churn.py.1’\n",
      "\n",
      "100%[======================================>] 1,309       --.-K/s   in 0s      \n",
      "\n",
      "2024-02-26 22:11:55 (69.4 MB/s) - ‘evaluate-churn.py.1’ saved [1309/1309]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/evaluate-churn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa0e98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-churn-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13ff7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_args = script_eval.run(\n",
    "     inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "                destination=\"/opt/ml/processing/model\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            )\n",
    "        ],\n",
    "    outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                             destination=f\"s3://{default_bucket}/output/evaluation\"),\n",
    "        ],\n",
    "    code=f\"evaluate-churn.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8afdc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ChurnEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"ChurnEvalModel\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7b5bc",
   "metadata": {},
   "source": [
    "## Define a register model step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f3f3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "model = Model(image_uri= image_uri,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08458230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac8339d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    \n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(name=\"ChurnRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb7687",
   "metadata": {},
   "source": [
    "## Condition step to check AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d628f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=auc_score_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff241f5",
   "metadata": {},
   "source": [
    "## Build and Trigger the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63d8093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Version': '2020-12-01', 'Metadata': {}, 'Parameters': [{'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1}, {'Name': 'ProcessingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'TrainingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'ModelApprovalStatus', 'Type': 'String', 'DefaultValue': 'PendingManualApproval'}], 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'}, 'TrialName': {'Get': 'Execution.PipelineExecutionId'}}, 'Steps': [{'Name': 'ChurnModelProcess', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge', 'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'}, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocess-churn.py']}, 'RoleArn': 'arn:aws:iam::021332873423:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/sagemaker-mlops-train-pipeline/ChurnModelProcess/input/input-1/storedata_total.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/sagemaker-mlops-train-pipeline/code/c570c64f24e8a2c6d8254de96925fe8e/preprocess-churn.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]}}}, {'Name': 'ChurnHyperParameterTuning', 'Type': 'Tuning', 'Arguments': {'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian', 'ResourceLimits': {'MaxNumberOfTrainingJobs': 2, 'MaxParallelTrainingJobs': 2}, 'TrainingJobEarlyStoppingType': 'Off', 'HyperParameterTuningJobObjective': {'Type': 'Maximize', 'MetricName': 'validation:auc'}, 'ParameterRanges': {'ContinuousParameterRanges': [{'Name': 'eta', 'MinValue': '0', 'MaxValue': '1', 'ScalingType': 'Auto'}, {'Name': 'min_child_weight', 'MinValue': '1', 'MaxValue': '10', 'ScalingType': 'Auto'}, {'Name': 'alpha', 'MinValue': '0', 'MaxValue': '2', 'ScalingType': 'Auto'}], 'CategoricalParameterRanges': [], 'IntegerParameterRanges': [{'Name': 'max_depth', 'MinValue': '4', 'MaxValue': '10', 'ScalingType': 'Auto'}]}}, 'TrainingJobDefinition': {'StaticHyperParameters': {'eval_metric': 'auc', 'objective': 'binary:logistic', 'num_round': '100', 'rate_drop': '0.3', 'tweedie_variance_power': '1.4'}, 'RoleArn': 'arn:aws:iam::021332873423:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole', 'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-021332873423/output'}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'HyperParameterTuningResourceConfig': {'InstanceCount': 1, 'InstanceType': {'Get': 'Parameters.TrainingInstanceType'}, 'VolumeSizeInGB': 30}, 'AlgorithmSpecification': {'TrainingInputMode': 'File', 'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'}, 'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'train'}, {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'validation'}]}}}, {'Name': 'ChurnEvalModel', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'}, 'InstanceCount': 1, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/evaluate-churn.py']}, 'RoleArn': 'arn:aws:iam::021332873423:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-us-east-1-021332873423', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"}, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/sagemaker-mlops-train-pipeline/code/41c6f8b85a79ce93b1bd4f4792842749/evaluate-churn.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-021332873423/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]}}, 'PropertyFiles': [{'PropertyFileName': 'ChurnEvaluationReport', 'OutputName': 'evaluation', 'FilePath': 'evaluation.json'}]}, {'Name': 'CheckAUCScoreChurnEvaluation', 'Type': 'Condition', 'Arguments': {'Conditions': [{'Type': 'GreaterThan', 'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.ChurnEvalModel.PropertyFiles.ChurnEvaluationReport'}, 'Path': 'classification_metrics.auc_score.value'}}, 'RightValue': 0.75}], 'IfSteps': [{'Name': 'ChurnRegisterModel-RegisterModel', 'Type': 'RegisterModel', 'Arguments': {'ModelPackageGroupName': 'ChurnModelPackageGroup', 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json', 'S3Uri': 's3://sagemaker-us-east-1-021332873423/output/evaluation/evaluation.json'}}, 'Bias': {}, 'Explainability': {}}, 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'Environment': {}, 'ModelDataUrl': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-us-east-1-021332873423', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}}], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv'], 'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.xlarge'], 'SupportedTransformInstanceTypes': ['ml.m5.xlarge']}, 'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'}, 'SkipModelValidation': 'None'}}], 'ElseSteps': []}}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(name= pipeline_name,\n",
    "                   parameters=[\n",
    "                       processing_instance_count,\n",
    "                       processing_instance_type,\n",
    "                       training_instance_type,\n",
    "                       model_approval_status,\n",
    "                       input_data,\n",
    "                       auc_score_threshold,\n",
    "                   ],\n",
    "                    steps=[step_process, step_tuning, step_eval, step_cond],)\n",
    "definition  = json.loads(pipeline.definition())\n",
    "print(definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dc3fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.start of <sagemaker.workflow.pipeline.Pipeline object at 0x7ff4b8d94760>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "# start Pipeline execution\n",
    "pipeline.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
